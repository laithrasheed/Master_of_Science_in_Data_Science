![image](https://github.com/laithrasheed/DTSA5304_Fundamentals_of_Data_Visualization/assets/124019127/031aa6ba-746d-459b-8eb0-3fdde64eac4b)

#   Resampling, Selection, and Splines [<sup>[1]</sup>](#reference-1)				

## Brief Description

- Consists of the foundational framework & application of cross-validation, bootstrapping, dimensionality reduction, ridge regression, lasso, GAMs and splines.


## Prior knowledge needed: 
##### [Statistical Inference](https://github.com/laithrasheed/MSDS_Program_Private/tree/main/Data%20Science%20Foundations/Statistical%20Inference)


## Learning Outcomes

- Apply resampling methods in order to obtain additional information about fitted models.
- Optimize fitting procedures to improve prediction accuracy and interpretability.
- Understand the benefits and approach of non-linear models.

## Resources

- Course Material

## Course Content

### Week 1    | Welcome and Review


#### Learning Objectives

- Review how non-parametric regression and GAMs differ from linear regression.
- Review the concept of a generalized linear model, its assumptions, and how it differs from linear regression

#### Programming Assignment

- Programming Assignments

### Week 2 |  Generalized Least Squares


#### Learning Objectives

- Describe how GLS extends the OLS method to account for heteroscedasticity and serial correlation.
- Use R to estimate the GLS coefficients and interpret the results.
- Evaluate the performance of GLS compared to OLS for a given dataset, and explain the reasons for any differences.

#### Programming Assignment

- Programming Assignments 

### Week 3   |  Shrink Methods


#### Learning Objectives

- Describe the differences between ridge regression, lasso regression, and principal component analysis.
- Apply ridge regression to a dataset with a large number of predictor variables and evaluate its effectiveness in reducing overfitting.
- Analyze the impact of different penalty parameters on the ridge regression model and interpret the results.
- Apply lasso regression to a dataset with a large number of predictor variables and evaluate its effectiveness in variable selection and reducing overfitting.
- Apply principal component analysis to a high-dimensional dataset and evaluate its effectiveness in reducing the number of dimensions.

#### Programming Assignment

- Programming Assignments  

### Week 4 | Cross Validation


#### Learning Objectives

- Identify the steps involved in implementing cross-validation in R programming.
- Analyze the results of cross-validation to compare different statistical learning models.
- Describe how cross-validation helps in assessing the generalization capability of statistical learning models.

#### Programming Assignment

- Programming Assignments 

### Week 5 |   Boostrapping


#### Learning Objectives

- Implement basic bootstrapping methods using R programming
- Interpret the results of a bootstrap analysis and understand their implications
- Describe the purpose and benefits of using bootstrapping in statistics

#### Programming Assignment

- Programming Assignments   


### Week 6 |  Final Exam

I have completed a multiple choice exam worth 25% of my grade.


## References
###### <a name="reference-1"></a>[[1] Course Curriculum - Master of Science in Data Science - University of Colorado Boulder](https://www.colorado.edu/program/data-science/coursera/curriculum/dtsa5021)
